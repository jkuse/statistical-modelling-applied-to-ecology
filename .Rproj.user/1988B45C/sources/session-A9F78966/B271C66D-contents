##################################################################
## Introducao a Modelagem Estatistica no R                      ##
## Codigo Aula 3 - Pratica - Regressao Linear e Limitacoes      ##
## PPGECO - UFSC - 20222                                        ##
## Preparado por: Fabio G. Daura-Jorge                          ##
##################################################################

### Codigo do material exposto na aula 3 (ppt) ###
### Adendos de multiplas fontes

## Re-Apresentando o Modelo Linear


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# 1. Ajustando o modelo e interpretando os parametros ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#

# Vamos usar novamente os dados de velocidade e distancia de parada
data(cars)
str(cars)
help(cars)

# Vamos ajustar um modelo linear aos dados
# Queremos prever a distacia de parada atraves da velocidade
lm(dist ~ speed, data=cars) -> reg.cars

# Vamos ver os resultados da analise
coef(reg.cars) # Podemos obter os coeficientes/betas estimados
confint(reg.cars) # Intervalo de confianca dos coeficientes

# Interpretando os coeficientes podemos dizer que:
# Quanto maior a velocidade, maior a distancia de parada
# Para cada milha por hora de velocidade, a distancia de parada
# aumenta 3.93 pes
# O intervalo de confianca da inclinacao da reta nao incluiu zero, portanto
# podemos afirmar com certa confianca que a relacao entre as duas
# variaveis foi significativa

# Vamos obter os resultados completos da analise com a funcao generica 'summary'
summary(reg.cars)

# Vamos olhar para a tabela com os coeficientes:
# Se dividirmos o valor estimado do coeficiente pelo seu erro padrao,
# obteremos o valor da estatistica t (da distribuicao t de Student) - a coluna
# 't value' da tabela
# Vamos tentar para a inclinacao:
3.9324/0.4155

# Queremos saber se o valor da inclinacao difere de zero,
# e isto depende do erro padrao. Se o erro for pequeno e o valor da inclinacao
# for alto, o numero de erros padroes que a inclinacao esta longe de zero 
# sera grande, e podemos concluir que existe uma relacao entre as variaveis, ou
# a inclinacao foi diferente de zero
# Em outras palavras, esta razao mede quao grande eh o coeficiente em relacao 
# a incerteza

# Esperamos que o valor estimado do coeficiente dividido pelo seu erro padrao
# siga uma distribuicao t com n-2 graus de liberdade
# Podemos calcular facilmente a probabilidade de obter um valor igual ou maior 
# que este usando a funcao 'pt' com o argumento 'lower.tail=FALSE'
# Multiplicamos a probabilidade por dois porque a reta pode ser tanto positiva 
# quanto negativa (teste bi-caudal)
2 * pt(9.46426, 48, lower.tail=FALSE)

# Os calculos bateram com a tabela! Agora vamos interpretar o valor de p:
# Assumindo que o valor da inclinacao seja igual a zero, existe uma probabilidade 
# muito pequena de obter este valor de t ao acaso, ou seja, concluimos que existe  
# uma associacao substancial entre a variavel resposta e a preditora, ou  
# a inclinacao foi diferente de zero. Rejeitamos a hipotese nula de nao associacao.

# Podemos ver que o intercepto tambem foi significativamente diferente de zero,
# ou seja, quando a variavel preditora for igual a zero, a variavel resposta sera
# diferente de zero. Para boa parte dos problemas usando regressao linear, testar
# se o intercepto difere de zero nao interessa o pesquisador. Neste caso nao faz 
# muito sentido.

# Vamos plotar em um grafico as duas variaveis e o que o modelo preve da relacao
# linear entre as duas
plot(dist ~ speed, data=cars)
abline(reg.cars, col="blue") ### line generated by the model

# Nem todos os pontos caem em cima da linha, ou seja, existe um ruido nos dados
# que o modelo nao preve. A diferenca entre o que o modelo preve e os dados 
# chama-se desvios ou erros residuais
# Obtemos estes erros atraves da funcao 'resid'
resid(reg.cars)

# Residuos na unha
cars$dist-fitted(reg.cars)  # Funcao 'fitted' extrai of valores 
# preditos pelo modelo para cada observacao

# Vamos plotar os erros residuais pelos valores preditos 
### which means residuals vs fitted
plot(resid(reg.cars) ~ fitted(reg.cars))
abline(h=0, lty=2)

# Como os residuos estao distribuidos? Eles parecem um ceu estrelado?
# Caso eles estejam distribuidos homogeneamente no grafico, parabens!
# Isto indica que o modelo foi valido. Qualquer padrao aberrante, com tendencias, 
# indica que este nao foi um bom modelo para seus dados.

# Mas seria melhor observar os residuos standardizados:
plot(rstandard(reg.cars) ~ fitted(reg.cars), ylab="Residuos standardizados",
     xlab="Valores preditos")
abline(h=0, lty=2)

# Melhor ainda sao os residuos studentizados
plot(rstudent(reg.cars) ~ fitted(reg.cars))
abline(h=0, lty=2)

# Podemos explorar mais os erros residuais
# Vamos ver se eles tem media zero
summary(rstudent(reg.cars))
?rstudent
# E a distribuicao normal?
hist(rstudent(reg.cars)) # Parece que sim, mas tem muito ruido em uma das caudas

# Outro grafico diagnostico
qqnorm(rstudent(reg.cars))
qqline(rstudent(reg.cars), col="red")

# Podemos checar a qualidade das previsoes do modelo pelo r quadrado
# Calculamos o r quadrado na unha
(cor(cars$dist,fitted(reg.cars)))^2 # Mas sempre melhor usar o r quadrado ajustado
summary(reg.cars)
# O modelo explica 65% na variabilidade de y

# Plotando os preditos pelo valores de y tambem vemos a qualidade da predicao 
plot(fitted(reg.cars), cars$dist, ylab="Distancia de parada",
     xlab="Valores preditos de y pelo modelo")
abline(0,1, col="red") # Esta eh a linha da predicao perfeita
# Se todos os pontos caissem nessa linha teriamos 
# um r quadrado igual a 1

# Outra forma de verificar qualidade do ajuste
# Plotando residuos pelos valores preditos
scatter.smooth(resid(reg.cars) ~ fitted(reg.cars))
abline(h=0, col="red")

# Vamos ver se existem observacoes influentes
influence.measures(reg.cars) # Veja as marcadas com asterisco

# Outra forma de ver observacoes influentes
plot(cooks.distance(reg.cars), ylab="Distancia de Cook", las=1)  

# Nenhum valor com distancia de Cook maior que 1,
# apesar de que uma das observacoes parece mais
# influente que as demais. Vale checar...

# Quatro graficos diagnosticos do modelo de forma facil e rapida
plot(reg.cars) # aperte o Enter para aparecer os plots

# Se eu quiser prever qual a distancia de parada a uma velocidade de 30 mph
-17.579+(3.9324*30)
coef(reg.cars)[1]+coef(reg.cars)[2]*30 ### using values from coef function to predict dist

# ou...
new <- data.frame(speed = 30)
predict(reg.cars, new) ### using the model to predict stop dist

# Agora quero prever com outro valor
new <- data.frame(speed = 2)
predict(reg.cars, new)  # Ops! O valor previsto foi negativo.
# Existe distancia negativa de parada?


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#
# 2. Um exemplo de aplicacao com uma serie temporal ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#

# Dados de concentracao de dioxido de carbono medida no topo do vulcao Mauna Loa
data(co2)

# Vamos plotar
plot(co2)

# Tendencia de aumento da concentracao fica evidente
# Mas queremos saber qual a taxa anual de aumento

# Vamos ajustar um modelo linear para verificar a tendencia da 
# concentracao atmosferica de co2 (variavel resposta) ao longo 
# dos anos (variavel explanatoria)

# Exploramos o objeto com os dados
co2
str(co2)
class(co2)  # Da classe 'time series', temos que manipular os dados pra
# ajustar o modelo aos dados

# Transformamos o objeto em um data-frame
data.frame(co2) -> co2.df

# Criamos duas novas variaveis (colunas) com os anos e os meses
rep(1:12, 39) -> co2.df$Mes
rep(1959:1997, each=12) -> co2.df$Ano

# Conferindo o novo data-frame
str(co2.df)

# Agora sim! Podemos ajustar o modelo...
lm(co2 ~ Ano, data=co2.df) -> lm.co2

# Interprete os resultados do modelo
summary(lm.co2)

# Vamos plotar os dados e a reta de regressao
with(co2.df, plot(Ano, co2))
abline(lm.co2, col="red", lwd=2) 

# Valide o modelo
par(mfrow = c(2,2))
plot(lm.co2)
par(mfrow = c(1,1))
dev.off()
# Interprete cada grafico...

# Vamos plotar os residuos do modelo pelo mes
plot(co2.df$Mes, resid(lm.co2))
# Podemos melhorar o modelo
# Existe uma variacao mensal. Vamos explorar um pouco mais...
boxplot(co2.df$co2 ~ co2.df$Mes)
plot(tapply(co2.df$co2, co2.df$Mes, mean))

# Podemos ajustar um modelo aditivo com ano e mes como variavel categorica
# Ou seja, cada mes tera um efeito proprio
lm(co2 ~ Ano + as.factor(Mes), data=co2.df) -> lm.co2.ad
summary(lm.co2.ad)
plot(lm.co2.ad)


# Agora vamos ajustar um modelo com efeito quadratico no mes
lm(co2 ~ Ano + Mes + I(Mes^2), data=co2.df) -> lm.co2.quad
summary(lm.co2.quad)
plot(lm.co2.quad)

# O que este modelo preve?
if(!require(effects)){install.packages("effects");library(effects)} ## explore tambem o pacote sjPlot

plot(allEffects(lm.co2.quad))

# Qual foi o melhor modelo?
AIC(lm.co2, lm.co2.ad, lm.co2.quad)
# A conclusao sobre a taxa de incremento anual de co2 na atmosfera mudou de
# acordo com o modelo? O que mudou de um modelo para o outro?

# Os dados sao independentes?
acf(co2)  # Uau!!! Altamente correlacionados...
# Padrao tipico de series temporais


#~~~~~~~~~~~~~~~~~~~~~~~~#
#  3. Exercicios ----
#~~~~~~~~~~~~~~~~~~~~~~~~#


# 3.1 Tendencia da populacao norte americana
data(uspop)
str(uspop)
summary(uspop)
head(uspop)
hist(uspop, nclass = 10)
?uspop
qqnorm(uspop)
qqline(uspop)
# Explore os dados, ajuste um modelo linear aos dados e calcule o incremento anual 
# da populacao. O crescimento foi significativo? Plote graficos diagnosticos e 
# discuta possiveis problemas deste modelo.

# Voce tambem pode calcular a taxa de crescimento instantanea da
# populacao (r) ajustando um modelo linear com a variavel resposta transformada
# no logaritmo natural (funcao 'log'). Neste caso a taxa de crescimento per capita
# sera a inclinacao da reta (beta 1). Ajuste este modelo aos dados.
# Este modelo corresponde a um modelo de crescimento exponencial.
# Gere uma previsao de quantos habitantes tera os EUA em 2050 e 2100.
# Dica: Lembre-se que para gerar a previsao voce tera que transformar novamente 
# o valor predito da variavel resposta para a escala real 
# (funcao anti-log natural = exponencial - funcao 'exp')


# 3.2 Comparando medidas florais de tres especies
data(iris)
??iris
summary(aov(iris[,1]~iris[,5]))

summary(lm(iris[,1]~iris[,5]))

# Queremos saber se as medidas florais variam entre tres especies.
# Explore os dados. Veja se existe correlacao entre as medidas florais.
# Escolha variaveis florais nao correlacionadas para testar a hipotese de que 
# as medidas florais variam entre as especies. Compare os resultados da 
# regressao com uma Analise de Variancia (funcao 'aov'). Qual sua conclusao?


# 3.3 Causas de acidentes em auto-estradas

# Vamos usar um banco de dados do pacote 'car'
library(car)
data(Highway1)
help(Highway1)
??Highway1

# Nossa pergunta: quais os fatores que interferem na taxa de acidentes?
# Explore os dados. Construa diferentes modelos e interprete-os. 
# As variaveis sao significativas? Qual o melhor modelo? Diagnostique se sao
# modelos validos. O que voce pode concluir com os dados?
